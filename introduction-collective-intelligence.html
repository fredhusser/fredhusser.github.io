<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Data Science for collective intelligence, ">

        <link rel="alternate"  href="http://fredhusser.github.io/feeds/all.atom.xml" type="application/atom+xml" title="Data Science for collective intelligence Full Atom Feed"/>

        <title>Part 0 - Collective intelligence in Python: introduction // Data Science for collective intelligence // </title>


    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.3.0/pure-min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.1.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="http://fredhusser.github.io/theme/css/pure.css">
    <link rel="stylesheet" href="http://fredhusser.github.io/theme/css/pygments.css">

    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/fitvids/1.0.1/jquery.fitvids.min.js"></script>
    <script>
        $(document).ready(function(){
            $(".content").fitVids();
        });
    </script>
</head>

<body>
<div class="pure-g-r" id="layout">
    <div class="sidebar sidebar-article pure-u">
        <header class="header-article">
            <hgroup>
                <a href="http://fredhusser.github.io/author/frederic-husser.html" title="See posts by Frederic Husser">
                </a>
                <h2 class="article-info">Frederic Husser</h2>
                <small class="about-author"></small>
                <h5>Published</h5>
                <p>jeu. 10 d√©cembre 2015</p>
                <a href="/">&larr;Home</a>
            </hgroup>
        </header>
    </div>
    <div class="pure-u">
        <div class="content">
            <section class="post">
                <header class="post-header">
                    <h1>Part 0 - Collective intelligence in Python: introduction</h1>
                        <p class="post-meta">
                            // under                                 <a class="post-category" href="http://fredhusser.github.io/tag/dev-environment.html">dev environment</a>
                                <a class="post-category" href="http://fredhusser.github.io/tag/machine-learning.html">Machine Learning</a>
                                <a class="post-category" href="http://fredhusser.github.io/tag/agile-data-science.html">Agile Data Science</a>
                        </p>
                </header>
            </section>
            <p>This blog is also meant to be a recipe for data scientists and physicists who want to be able to present and communicate about their work, so that their algorithms and analysis do not sleep forever deep in their GitHub account.</p>
<h2 id="so-what-are-the-goals-we-want-to-pursue">So what are the goals we want to pursue?</h2>
<p>We want to build an application that collects a great number of blog posts, news articles or opinions in the web, use a semantic analysis to classify them based on content and allows users to browse faster in the corpus through a simple web application.</p>
<p>In this blog we intend to present some tools for doing data analysis with Python but also we want to propose a way to conduct data analysis projects. The goals are to reduce the frictions in the full process. Frictions stem usually from the difficulty to work together for people with different backgrounds and fields: developers, data scientists, users and consummers. </p>
<p>The lean data science is based upon the principle that data collection, analysis and visualization should be considered as a loop that must be completed at the fastest possible speed. At each iteration, developers and data scientists can work collaboratively to improve the solution at any level as they can see the full picture. So let's get to work.</p>
<h2 id="mission-objectives-and-roadmap">Mission, objectives and roadmap</h2>
<h3 id="mission">Mission</h3>
<p>Our mission is to build a intelligent news web application able to classify and cluster articles and opinions. It must offer to users a simple but complete browsing experience, so that they can reach the biggest amount of relevant content in the least amount of time. Documents relevance is assessed using:</p>
<ul>
<li><strong>semantic analysis</strong>, that is to say extract features from the textual content, </li>
<li><strong>collaborative filtering</strong> that is to say extract features on documents based on how users interact with them (likes, shares, comments).</li>
</ul>
<h3 id="objectives">Objectives</h3>
<p>In order to realize this mission we can set up few objectives and constraints. First and foremost, we want to be <strong>open source</strong> and <strong>transparent</strong>. When using machine learning algorithms with the aim of recommending content to users it is immensely necessary to be open to critics so that it acknowledged by users to be fair and not pursuing self-interests. </p>
<p>Secondly, we do not seek the ultimate model and algorithm that will unequivocally resolve the challenge. Instead, algorithms must be combined, confronted and strongly challenged. There is no debate on whether model-based recommendations are better that collaborative filtering when it comes to recommending content. Instead, it must be recognized that both have strengths and weeknesses and therefore the question is how to make them operate together.</p>
<p>Finally, we want to offer to users the capability to browse quickly in the documents although the corpus is meant to be important. The classification and clustering algorithms must integrate this objective so that documents indexing is perfectly matching the requirements of a smart data visualization.</p>
<h3 id="roadmap">Roadmap</h3>
<p>In the first iteration we will tackle the issue of semantic analysis for classifying documents based on their content. In order to achieve this goal we will operate in an agile manner so that we complete the following steps the fastest possible.</p>
<ol>
<li>
<p><strong>Environment set-up</strong>
We will set up a reproducible development environment, with all the basic tools and frameworks we are going to need. For this we will be using Vagrant for taking care of our virtual machine on which to run Python scripts and Docker containers.</p>
</li>
<li>
<p><strong>Data Collection</strong>
Then some input data will be scraped from the web in order to have a collection of articles on which to perform some analysis. We will use Scrapy, a web scraper in made in Python, to help us crawling articles from <a href="http://www.lemonde.fr"><em>www.lemonde.fr</em></a>.</p>
</li>
<li>
<p><strong>Data analytics and text mining</strong>
Here is the hard work! Standing on the shoulder of giants like Numpy, NLTK and Scikit-Learn, we will build a document classification algorithm based on semantic analysis and self-organizing maps. We will rely a lot on the existing algorithms for natural language processing (NLP) such as in Scikit-Learn and NLTK, and we will eventually build our own self-organizing map classifier in Python.</p>
</li>
<li>
<p><strong>Data visualization and browsing</strong>
Building a light weight web application with Flask and pymongo, we will make possible to data scientists to communicate on their results, with a step-by-step workflow.</p>
</li>
<li>
<p>Present atomic records or chunks of the data; in our case it will be the news articles crawled from lemonde.fr. This step is really important to complete so that you can also evaluate the quality of your raw data. Keep the iteration based mindset.</p>
</li>
<li>
<p>Build data visualizations for presenting the results of your analysis, enabling the user to understand the full scope of it. We want also to make the data scientists able to evaluate the quality of the analysis they performed with an objective point of view.</p>
</li>
<li>
<p>Create reports that convey a message understandable by your audience. These reports are based on the analysis you conducted. For instance, what are the hot topics, the most transversal articles or the most specific ones? The value of your analysis is derived from the insight on the data it can give and the actions that can be taken.</p>
</li>
</ol>
            <div class="hr"></div>
            <a href="#" class="go-top">Go Top</a>
<footer class="footer">
    <p>&copy; Data Science for collective intelligence &ndash;
        Built with <a href="https://github.com/PurePelicanTheme/pure">Pure Theme</a>
        for <a href="http://blog.getpelican.com/">Pelican</a>
    </p>
</footer>        </div>
    </div>
</div>
    <script>
        var $top = $('.go-top');

        // Show or hide the sticky footer button
        $(window).scroll(function() {
            if ($(this).scrollTop() > 200) {
                $top.fadeIn(200);
            } else {
                $top.fadeOut(200);
            }
        });

        // Animate the scroll to top
        $top.click(function(event) {
            event.preventDefault();
            $('html, body').animate({scrollTop: 0}, 300);
        })

        // Makes sure that the href="#" attached to the <a> elements
        // don't scroll you back up the page.
        $('body').on('click', 'a[href="#"]', function(event) {
            event.preventDefault();
        });
    </script>
</body>
</html>